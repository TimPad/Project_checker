import streamlit as st
from openai import OpenAI
import json
from pptx import Presentation
import io
import pandas as pd
import fitz

# --- –ù–∞—á–∞–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ ---
st.set_page_config(
    page_title="–≠–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –∫ –∑–∞—â–∏—Ç–µ",
    page_icon="ü§ñ",
    layout="wide"
)

EXAMPLE_STORYTELLING_TEXT = """–î–æ–±—Ä—ã–π –¥–µ–Ω—å, —É–≤–∞–∂–∞–µ–º—ã–µ –∫–æ–ª–ª–µ–≥–∏, —ç–∫—Å–ø–µ—Ä—Ç—ã –∏ –ø–∞—Ä—Ç–Ω—ë—Ä—ã.
... (—Å–æ–∫—Ä–∞—â–µ–Ω–æ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏) ...
"""

@st.cache_resource
def get_openai_client():
    try:
        client = OpenAI(
            api_key=st.secrets["DEEPSEEK_API_KEY"],
            base_url="https://api.studio.nebius.ai/v1/"
        )
        return client
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ API: {e}")
        return None

client = get_openai_client()

def extract_text_from_pptx(uploaded_file):
    try:
        pptx_buffer = io.BytesIO(uploaded_file.getvalue())
        prs = Presentation(pptx_buffer)
        text_runs = []
        for slide in prs.slides:
            for shape in slide.shapes:
                if not shape.has_text_frame:
                    continue
                for paragraph in shape.text_frame.paragraphs:
                    for run in paragraph.runs:
                        text_runs.append(run.text)
        return "\n".join(text_runs)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
        return ""

def extract_text_from_pdf(uploaded_file):
    try:
        pdf_bytes = uploaded_file.getvalue()
        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            return "\n".join([page.get_text() for page in doc])
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF-—Ñ–∞–π–ª–∞: {e}")
        return ""

def get_analysis_from_deepseek(project_text: str, tone: str):
    if not client:
        return None

    storytelling_instruction = f"""
"storytelling_script": –û–±—ä–µ–∫—Ç —Å–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–º –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è (5‚Äì7 –º–∏–Ω—É—Ç), –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–º –≤ –∂–∞–Ω—Ä–µ {tone.lower()} —Å—Ç–æ—Ä–∏—Ç–µ–ª–ª–∏–Ω–≥–∞, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –ø—Ä–æ–∏–∑–Ω–µ—Å—Ç–∏ –≤—Å–ª—É—Ö –ø–µ—Ä–µ–¥ –∂—é—Ä–∏. –û–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ª–æ–≥–∏—á–Ω—ã–º, —É–±–µ–¥–∏—Ç–µ–ª—å–Ω—ã–º, —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ —Ç—Ä—ë–º –±–ª–æ–∫–∞–º:

- "introduction": —è—Ä–∫–æ–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ (‚âà1 –º–∏–Ω—É—Ç–∞), –≤ –∫–æ—Ç–æ—Ä–æ–º —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–∞, –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–Ω—Ç–µ—Ä–µ—Å –∏ –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç—Å—è –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞.
- "main_part": –æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å (‚âà3‚Äì5 –º–∏–Ω—É—Ç), –≥–¥–µ —Ä–∞—Å–∫—Ä—ã–≤–∞—é—Ç—Å—è: –∑–∞—á–µ–º –ø—Ä–æ–µ–∫—Ç –Ω—É–∂–µ–Ω, –∫–∞–∫ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç, –≤ —á—ë–º –Ω–æ–≤–∏–∑–Ω–∞, —Ö–æ–¥ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–Ω–∞–ª–æ–≥–∞–º–∏.
- "conclusion": —Ñ–∏–Ω–∞–ª (‚âà1 –º–∏–Ω—É—Ç–∞), –≤ –∫–æ—Ç–æ—Ä–æ–º –ø–æ–¥–≤–æ–¥—è—Ç—Å—è –∏—Ç–æ–≥–∏, –æ–∑–≤—É—á–∏–≤–∞—é—Ç—Å—è –ø–ª–∞–Ω—ã –∏ –¥–µ–ª–∞–µ—Ç—Å—è –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –æ–±—â–µ—Å—Ç–≤–∞, –ø—Ä–∏—Ä–æ–¥—ã –∏–ª–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π.

–°—Ç–∏–ª—å —Ä–µ—á–∏ ‚Äî –∂–∏–≤–æ–π, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π, –∞–¥—Ä–µ—Å–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç–∞–º –∏ –ø–∞—Ä—Ç–Ω—ë—Ä–∞–º. –ë–µ–∑ –∫–ª–∏—à–µ, —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏, —Ä–∏—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏, –æ–±—Ä–∞–∑–∞–º–∏. –ú–∞–∫—Å–∏–º—É–º –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏, –º–∏–Ω–∏–º—É–º –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π.
"""

    prompt = f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ü–µ–Ω–∫–µ —É—á–µ–±–Ω–æ-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∏ –ø—Ä–æ–µ–∫—Ç–Ω—ã—Ö —Ä–∞–±–æ—Ç —à–∫–æ–ª—å–Ω–∏–∫–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≤–µ—Ä–Ω—É—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ **–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON-–æ–±—ä–µ–∫—Ç–∞** —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:

1. "strengths": –°–ø–∏—Å–æ–∫ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω –ø—Ä–æ–µ–∫—Ç–∞ (–º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫).
2. "weaknesses": –°–ø–∏—Å–æ–∫ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω –∏ –∑–æ–Ω –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å –∫—Ä–∞—Ç–∫–∏–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ (–º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫).
3. "fact_check": –ü—Ä–æ–≤–µ—Ä–∫–∞ 3‚Äì5 –∫–ª—é—á–µ–≤—ã—Ö —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π. –ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å "claim", "verdict" ('–ò—Å—Ç–∏–Ω–∞', '–õ–æ–∂—å', '–ù–µ–ø—Ä–æ–≤–µ—Ä—è–µ–º–æ/–¢—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è') –∏ "explanation".
4. {storytelling_instruction.strip()}
5. "tricky_questions": –°–ø–∏—Å–æ–∫ –∏–∑ 5 –∫–∞–≤–µ—Ä–∑–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (–º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫).

–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –ø—Ä–æ–µ–∫—Ç–∞:
{project_text}
"""

    try:
        response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-R1",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6,
            top_p=0.9,
            max_tokens=2048,
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ API DeepSeek: {e}")
        return None

# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
st.title("ü§ñ –≠–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –∫ –∑–∞—â–∏—Ç–µ")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é (`.pdf`, `.pptx`) –∏/–∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–æ–∫–ª–∞–¥–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.")

col1, col2 = st.columns(2)

with col1:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é (PDF –∏–ª–∏ PPTX)", type=["pptx", "pdf"])

with col2:
    def load_example_text():
        st.session_state.report_text_input = EXAMPLE_STORYTELLING_TEXT

    if "report_text_input" not in st.session_state:
        st.session_state.report_text_input = ""

    report_text = st.text_area(
        "–í—Å—Ç–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–æ–∫–ª–∞–¥–∞",
        height=218,
        placeholder="–ó–¥–µ—Å—å –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–∞—à —Å—Ü–µ–Ω–∞—Ä–∏–π –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è...",
        key="report_text_input"
    )

    st.button("‚úçÔ∏è –í—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞", on_click=load_example_text, use_container_width=True)

tone = st.selectbox("üé≠ –í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–∏–ª—å —Å—Ü–µ–Ω–∞—Ä–∏—è –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è", ["–í–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–π", "–§–æ—Ä–º–∞–ª—å–Ω—ã–π", "–ù–∞—É—á–Ω–æ-–ø–æ–ø—É–ª—è—Ä–Ω—ã–π"], index=0)

if st.button("üöÄ –ü—Ä–æ–≤–µ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –ø—Ä–æ–µ–∫—Ç–∞", type="primary", use_container_width=True):
    project_text = ""
    if uploaded_file is not None:
        with st.spinner("–ò–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞..."):
            file_name = uploaded_file.name.lower()
            if file_name.endswith('.pptx'):
                project_text = extract_text_from_pptx(uploaded_file)
            elif file_name.endswith('.pdf'):
                project_text = extract_text_from_pdf(uploaded_file)

    combined_text = (project_text + "\n\n" + report_text).strip()

    if not combined_text:
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
    else:
        with st.spinner("–ò–ò-—ç–∫—Å–ø–µ—Ä—Ç –∏–∑—É—á–∞–µ—Ç –≤–∞—à –ø—Ä–æ–µ–∫—Ç... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ 2 –º–∏–Ω—É—Ç."):
            analysis_result = get_analysis_from_deepseek(combined_text, tone)

        if analysis_result:
            st.success("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –í–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")

            col_strengths, col_weaknesses = st.columns(2)
            with col_strengths:
                st.subheader("üëç –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã")
                for s in analysis_result.get("strengths", []):
                    st.markdown(f"- {s}")

            with col_weaknesses:
                st.subheader("ü§î –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã")
                for w in analysis_result.get("weaknesses", []):
                    st.markdown(f"- {w}")

            st.divider()

            st.header("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–∫—Ç–æ–≤")
            facts = analysis_result.get("fact_check", [])
            if facts:
                df = pd.DataFrame(facts)
                df.columns = ["–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ", "–í–µ—Ä–¥–∏–∫—Ç", "–ü–æ—è—Å–Ω–µ–Ω–∏–µ"]
                st.dataframe(df, use_container_width=True, hide_index=True)
            else:
                st.info("–§–∞–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –±—ã–ª–∏ –≤—ã–¥–µ–ª–µ–Ω—ã.")

            st.divider()

            st.header("üé§ –°—Ü–µ–Ω–∞—Ä–∏–π –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è")
            script = analysis_result.get("storytelling_script", {})
            with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–π", expanded=True):
                st.subheader("–í—Å—Ç—É–ø–ª–µ–Ω–∏–µ")
                st.markdown(script.get("introduction", "_–ù–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ_"))
                st.subheader("–û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å")
                st.markdown(script.get("main_part", "_–ù–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ_"))
                st.subheader("–ó–∞–∫–ª—é—á–µ–Ω–∏–µ")
                st.markdown(script.get("conclusion", "_–ù–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ_"))

            st.divider()

            st.header("ü§î –ö–∞–≤–µ—Ä–∑–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã")
            for i, q in enumerate(analysis_result.get("tricky_questions", []), 1):
                st.markdown(f"**{i}.** {q}")
        else:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–µ–∫—Å—Ç –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
